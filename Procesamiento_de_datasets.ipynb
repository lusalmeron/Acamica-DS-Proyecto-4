{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Procesamiento de datasets\n",
    "En este notebook están agrupados los procedimientos por los cuales se importaron, concatenaron y procesaron los sets de datos originalmente provistos:\n",
    "- `dataset_es_dev.json`\n",
    "- `dataset_es_train.json`\n",
    "- `dataset_es_test.json`\n",
    "\n",
    "Para generar sets de datos con los atributos relevantes y las reviews lemmatizadas y stemmatizadas, segpun el caso:\n",
    "- `dataset_amazon_reviews_lemma.json`\n",
    "- `dataset_amazon_reviews_stem.json`\n",
    "\n",
    "De esta forma, se ahorra tiempo en la ejecución del notebook que resulve la consigna pedida.\n",
    "\n",
    "### Importar las librerías necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Garbage collector para optimizar recursos\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Previamente\n",
    "## python -m spacy download es\n",
    "## python -m spacy download es_core_news_sm\n",
    "\n",
    "import spacy # https://spacy.io/usage/models\n",
    "nlp = spacy.load('en_core_web_md')\n",
    "\n",
    "#Stop Words de en_core_news_md\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "stopwords_spacy = list(STOP_WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "#Stop Words de nltk\n",
    "from nltk.corpus import stopwords\n",
    "stopwords_nltk = set(stopwords.words('english'))\n",
    "\n",
    "import re\n",
    "from nltk.tokenize import RegexpTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clase para personalizar las impresiones de consola\n",
    "class color:\n",
    "   PURPLE = '\\033[95m'\n",
    "   CYAN = '\\033[96m'\n",
    "   DARKCYAN = '\\033[36m'\n",
    "   BLUE = '\\033[94m'\n",
    "   GREEN = '\\033[92m'\n",
    "   YELLOW = '\\033[93m'\n",
    "   RED = '\\033[91m'\n",
    "   BOLD = '\\033[1m'\n",
    "   UNDERLINE = '\\033[4m'\n",
    "   END = '\\033[0m'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importar el dataset original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Cantidad de filas del set:\u001b[93m 23486 \u001b[0m\n",
      "- Cantidad de atributos (columnas) del dataset:\u001b[96m 11 \u001b[0m\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"data/Womens_Clothing_Reviews.csv\")\n",
    "print(\"- Cantidad de filas del set:\" + color.YELLOW, data.shape[0],color.END)\n",
    "print(\"- Cantidad de atributos (columnas) del dataset:\" + color.CYAN, data.shape[1],color.END)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtrado de columnas\n",
    "Nos quedamos con las columnas del dataset que son relevantes para predecir la valoración en general. Por eso se descartan las columnas de id de usuario y producto. La de categoría nos puede servir para relacionar palabras. La del idioma es redundante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class_name</th>\n",
       "      <th>clothing_id</th>\n",
       "      <th>usr_age</th>\n",
       "      <th>review_title</th>\n",
       "      <th>review_body</th>\n",
       "      <th>rating</th>\n",
       "      <th>recommended</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Intimates</td>\n",
       "      <td>767</td>\n",
       "      <td>33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Absolutely wonderful - silky and sexy and comf...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dresses</td>\n",
       "      <td>1080</td>\n",
       "      <td>34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Love this dress!  it's sooo pretty.  i happene...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dresses</td>\n",
       "      <td>1077</td>\n",
       "      <td>60</td>\n",
       "      <td>Some major design flaws</td>\n",
       "      <td>I had such high hopes for this dress and reall...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pants</td>\n",
       "      <td>1049</td>\n",
       "      <td>50</td>\n",
       "      <td>My favorite buy!</td>\n",
       "      <td>I love, love, love this jumpsuit. it's fun, fl...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Blouses</td>\n",
       "      <td>847</td>\n",
       "      <td>47</td>\n",
       "      <td>Flattering shirt</td>\n",
       "      <td>This shirt is very flattering to all due to th...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  class_name  clothing_id  usr_age             review_title  \\\n",
       "0  Intimates          767       33                      NaN   \n",
       "1    Dresses         1080       34                      NaN   \n",
       "2    Dresses         1077       60  Some major design flaws   \n",
       "3      Pants         1049       50         My favorite buy!   \n",
       "4    Blouses          847       47         Flattering shirt   \n",
       "\n",
       "                                         review_body  rating  recommended  \n",
       "0  Absolutely wonderful - silky and sexy and comf...       4            1  \n",
       "1  Love this dress!  it's sooo pretty.  i happene...       5            1  \n",
       "2  I had such high hopes for this dress and reall...       3            0  \n",
       "3  I love, love, love this jumpsuit. it's fun, fl...       5            1  \n",
       "4  This shirt is very flattering to all due to th...       5            1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filtramos columnas y las renombramos para mayor facilidad de uso\n",
    "data = data[['Class Name','Clothing ID','Age','Title','Review Text','Rating','Recommended IND']]\n",
    "mapper = {'Clothing ID':'clothing_id', 'Age':'usr_age', 'Title':'review_title', 'Review Text':'review_body', 'Rating':'rating',\n",
    "       'Recommended IND':'recommended', 'Class Name':'class_name'}\n",
    "data.rename(columns=mapper,inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limpieza de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class_name      0.0\n",
       "clothing_id     0.0\n",
       "usr_age         0.0\n",
       "review_title    0.0\n",
       "review_body     0.0\n",
       "rating          0.0\n",
       "recommended     0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tratamiento de nulos\n",
    "df  = data.copy()\n",
    "df.fillna(value={'review_title':\"-\"}, inplace=True)\n",
    "df = df.dropna()\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Porcentaje de nulos por columna\n",
    "df.isna().sum()*100/df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Constante de signos de puntuación\n",
    "import string\n",
    "puntua = string.punctuation + '#...'\n",
    "excluded_pos = ['SCONJ','CCONJ','NUM','PUNCT','PRON','DET','ADP','AUX','X']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Función para limpieza de datos con lemmatizer\n",
    "def text_data_lemma(sentence):\n",
    "    doc = nlp(sentence)\n",
    "    \n",
    "    clean_tokens = []\n",
    "    for token in doc:\n",
    "        if (token.pos_ not in excluded_pos and str(token) not in stopwords_spacy and len(token.text)>2): \n",
    "            temp = token.lemma_.strip()\n",
    "            clean_tokens.append(temp.lower())\n",
    "    \n",
    "    return clean_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import *\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "#Función para limpieza de datos con stemmer\n",
    "def text_data_stem(sentence):\n",
    "    doc = nlp(sentence)\n",
    "    \n",
    "    clean_tokens = []\n",
    "    for token in doc:\n",
    "        if (token.pos_ not in excluded_pos and str(token) not in stopwords_spacy and len(token.text)>2): \n",
    "            temp = stemmer.stem(token.text).strip()\n",
    "            clean_tokens.append(temp.lower())\n",
    "    \n",
    "    return clean_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lemmatización (15 min aprox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['absolutely wonderful silky sexy comfortable',\n",
       " 'love dress sooo pretty happen find store glad order online petite buy petite love length me- hit little knee definitely true midi truly petite',\n",
       " 'major design flaw high hope dress want work initially order petite small usual size find outrageously small small fact zip reorder petite medium overall half comfortable fit nicely half tight layer somewhat cheap net layer imo major design flaw net layer sew directly zipper',\n",
       " 'favorite buy love love love jumpsuit fun flirty fabulous time wear great compliment',\n",
       " 'flattering shirt shirt flattering adjustable tie perfect length wear legging sleeveless pair cardigan love shirt']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Limpiamos todas las reviews con lemmatizer\n",
    "reviews_lemma = []\n",
    "for i in df.index:\n",
    "    rev = text_data_lemma(df.review_title.iloc[i] + ' ' + df.review_body.iloc[i])\n",
    "    reviews_lemma.append(\" \".join(rev))\n",
    "reviews_lemma[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stemmización (40 min aprox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpiamos todas las reviews con stemmizer\n",
    "reviews_stem = []\n",
    "for i in df.index:\n",
    "    rev = text_data_stem(df.review_title.iloc[i] + ' ' + df.review_body.iloc[i])\n",
    "    reviews_stem.append(\" \".join(rev))\n",
    "reviews_stem[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guardar nuevos datos en achivo .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agregamos columna al dataset\n",
    "df['revs_lemma'] = reviews_lemma\n",
    "df['revs_stem'] = reviews_stem\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardamos dataset lemmatizado\n",
    "df.to_csv(path_or_buf='data/dataset_clothes_clean.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
