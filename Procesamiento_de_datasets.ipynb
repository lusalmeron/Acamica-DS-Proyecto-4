{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Procesamiento de datasets\n",
    "En este notebook están agrupados los procedimientos por los cuales se importaron y procesaron los datos originalmente provistos en el set `Womens_Clothing_Reviews.csv` para generar un set de datos con los atributos relevantes y las reviews lemmatizadas y stemmatizadas como columnas aparte. Así se obtiene el archivo: `dataset_clothes_clean.csv`.\n",
    "\n",
    "De esta forma se ahorra tiempo en la ejecución del notebook que resulve la consigna pedida.\n",
    "\n",
    "### Importar las librerías necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Garbage collector para optimizar recursos\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Previamente\n",
    "## python -m spacy download en_core_web_md\n",
    "\n",
    "import spacy # https://spacy.io/usage/models\n",
    "nlp = spacy.load('en_core_web_md')\n",
    "\n",
    "#Stop Words de en_core_news_md\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "stopwords_spacy = list(STOP_WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "#Stop Words de nltk\n",
    "from nltk.corpus import stopwords\n",
    "stopwords_nltk = set(stopwords.words('english'))\n",
    "\n",
    "import re\n",
    "from nltk.tokenize import RegexpTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clase para personalizar las impresiones de consola\n",
    "class color:\n",
    "   PURPLE = '\\033[95m'\n",
    "   CYAN = '\\033[96m'\n",
    "   DARKCYAN = '\\033[36m'\n",
    "   BLUE = '\\033[94m'\n",
    "   GREEN = '\\033[92m'\n",
    "   YELLOW = '\\033[93m'\n",
    "   RED = '\\033[91m'\n",
    "   BOLD = '\\033[1m'\n",
    "   UNDERLINE = '\\033[4m'\n",
    "   END = '\\033[0m'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importar el dataset original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Cantidad de filas del set:\u001b[93m 23486 \u001b[0m\n",
      "- Cantidad de atributos (columnas) del dataset:\u001b[96m 11 \u001b[0m\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"data/Womens_Clothing_Reviews.csv\")\n",
    "print(\"- Cantidad de filas del set:\" + color.YELLOW, data.shape[0],color.END)\n",
    "print(\"- Cantidad de atributos (columnas) del dataset:\" + color.CYAN, data.shape[1],color.END)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtrado de columnas\n",
    "Nos quedamos con las columnas del dataset que son relevantes para predecir si una prenda será recomendada o no. Por eso se descartan las columnas de `Positive Feedback Count`, `Division Name` y `Department Name`. La de clase nos puede servir para relacionar palabras y la de edad podría tener alguna influencia en el resultado final. El id de la prenda, si bien muy probablemente no sirva para la predicción, sí sirve para el análisis exploratorio y entender a qué prendas en particular se hace referencia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class_name</th>\n",
       "      <th>clothing_id</th>\n",
       "      <th>usr_age</th>\n",
       "      <th>review_title</th>\n",
       "      <th>review_body</th>\n",
       "      <th>rating</th>\n",
       "      <th>recommended</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Intimates</td>\n",
       "      <td>767</td>\n",
       "      <td>33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Absolutely wonderful - silky and sexy and comf...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dresses</td>\n",
       "      <td>1080</td>\n",
       "      <td>34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Love this dress!  it's sooo pretty.  i happene...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dresses</td>\n",
       "      <td>1077</td>\n",
       "      <td>60</td>\n",
       "      <td>Some major design flaws</td>\n",
       "      <td>I had such high hopes for this dress and reall...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pants</td>\n",
       "      <td>1049</td>\n",
       "      <td>50</td>\n",
       "      <td>My favorite buy!</td>\n",
       "      <td>I love, love, love this jumpsuit. it's fun, fl...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Blouses</td>\n",
       "      <td>847</td>\n",
       "      <td>47</td>\n",
       "      <td>Flattering shirt</td>\n",
       "      <td>This shirt is very flattering to all due to th...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  class_name  clothing_id  usr_age             review_title  \\\n",
       "0  Intimates          767       33                      NaN   \n",
       "1    Dresses         1080       34                      NaN   \n",
       "2    Dresses         1077       60  Some major design flaws   \n",
       "3      Pants         1049       50         My favorite buy!   \n",
       "4    Blouses          847       47         Flattering shirt   \n",
       "\n",
       "                                         review_body  rating  recommended  \n",
       "0  Absolutely wonderful - silky and sexy and comf...       4            1  \n",
       "1  Love this dress!  it's sooo pretty.  i happene...       5            1  \n",
       "2  I had such high hopes for this dress and reall...       3            0  \n",
       "3  I love, love, love this jumpsuit. it's fun, fl...       5            1  \n",
       "4  This shirt is very flattering to all due to th...       5            1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filtramos columnas y las renombramos para mayor facilidad de uso\n",
    "data = data[['Class Name','Clothing ID','Age','Title','Review Text','Rating','Recommended IND']]\n",
    "mapper = {'Clothing ID':'clothing_id', 'Age':'usr_age', 'Title':'review_title', 'Review Text':'review_body', 'Rating':'rating',\n",
    "       'Recommended IND':'recommended', 'Class Name':'class_name'}\n",
    "data.rename(columns=mapper,inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limpieza de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class_name      0.0\n",
       "clothing_id     0.0\n",
       "usr_age         0.0\n",
       "review_title    0.0\n",
       "review_body     0.0\n",
       "rating          0.0\n",
       "recommended     0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tratamiento de nulos\n",
    "df  = data.copy()\n",
    "df.fillna(value={'review_title':\"-\"}, inplace=True)\n",
    "df = df.dropna()\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Porcentaje de nulos por columna\n",
    "df.isna().sum()*100/df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Constante de signos de puntuación\n",
    "import string\n",
    "puntua = string.punctuation + '#...'\n",
    "excluded_pos = ['SCONJ','CCONJ','NUM','PUNCT','PRON','DET','ADP','AUX','X']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Función para limpieza de datos con lemmatizer\n",
    "def text_data_lemma(sentence):\n",
    "    doc = nlp(sentence)\n",
    "    \n",
    "    clean_tokens = []\n",
    "    for token in doc:\n",
    "        if (token.pos_ not in excluded_pos and str(token) not in stopwords_spacy and len(token.text)>2): \n",
    "            temp = token.lemma_.strip()\n",
    "            clean_tokens.append(temp.lower())\n",
    "    \n",
    "    return clean_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import *\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "#Función para limpieza de datos con stemmer\n",
    "def text_data_stem(sentence):\n",
    "    doc = nlp(sentence)\n",
    "    \n",
    "    clean_tokens = []\n",
    "    for token in doc:\n",
    "        if (token.pos_ not in excluded_pos and str(token) not in stopwords_spacy and len(token.text)>2): \n",
    "            temp = stemmer.stem(token.text).strip()\n",
    "            clean_tokens.append(temp.lower())\n",
    "    \n",
    "    return clean_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lemmatización (10 min aprox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['absolutely wonderful silky sexy comfortable',\n",
       " 'love dress sooo pretty happen find store glad order online petite buy petite love length me- hit little knee definitely true midi truly petite',\n",
       " 'major design flaw high hope dress want work initially order petite small usual size find outrageously small small fact zip reorder petite medium overall half comfortable fit nicely half tight layer somewhat cheap net layer imo major design flaw net layer sew directly zipper',\n",
       " 'favorite buy love love love jumpsuit fun flirty fabulous time wear great compliment',\n",
       " 'flattering shirt shirt flattering adjustable tie perfect length wear legging sleeveless pair cardigan love shirt']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Limpiamos todas las reviews con lemmatizer\n",
    "reviews_lemma = []\n",
    "for i in df.index:\n",
    "    rev = text_data_lemma(df.review_title.iloc[i] + ' ' + df.review_body.iloc[i])\n",
    "    reviews_lemma.append(\" \".join(rev))\n",
    "reviews_lemma[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stemmización (10 min aprox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['absolut wonder silki sexi comfort',\n",
       " 'love dress sooo pretti happen find store glad order onlin petit bought petit love length me- hit littl knee definit true midi truli petit',\n",
       " 'major design flaw high hope dress want work initi order petit small usual size found outrag small small fact zip reorder petit medium overal half comfort fit nice half tight layer somewhat cheap net layer imo major design flaw net layer sewn directli zipper',\n",
       " 'favorit buy love love love jumpsuit fun flirti fabul time wear great compliment',\n",
       " 'flatter shirt shirt flatter adjust tie perfect length wear leg sleeveless pair cardigan love shirt']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Limpiamos todas las reviews con stemmizer\n",
    "reviews_stem = []\n",
    "for i in df.index:\n",
    "    rev = text_data_stem(df.review_title.iloc[i] + ' ' + df.review_body.iloc[i])\n",
    "    reviews_stem.append(\" \".join(rev))\n",
    "reviews_stem[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guardar nuevos datos en achivo .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class_name</th>\n",
       "      <th>clothing_id</th>\n",
       "      <th>usr_age</th>\n",
       "      <th>review_title</th>\n",
       "      <th>review_body</th>\n",
       "      <th>rating</th>\n",
       "      <th>recommended</th>\n",
       "      <th>revs_lemma</th>\n",
       "      <th>revs_stem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Intimates</td>\n",
       "      <td>767</td>\n",
       "      <td>33</td>\n",
       "      <td>-</td>\n",
       "      <td>Absolutely wonderful - silky and sexy and comf...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>absolutely wonderful silky sexy comfortable</td>\n",
       "      <td>absolut wonder silki sexi comfort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dresses</td>\n",
       "      <td>1080</td>\n",
       "      <td>34</td>\n",
       "      <td>-</td>\n",
       "      <td>Love this dress!  it's sooo pretty.  i happene...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>love dress sooo pretty happen find store glad ...</td>\n",
       "      <td>love dress sooo pretti happen find store glad ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dresses</td>\n",
       "      <td>1077</td>\n",
       "      <td>60</td>\n",
       "      <td>Some major design flaws</td>\n",
       "      <td>I had such high hopes for this dress and reall...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>major design flaw high hope dress want work in...</td>\n",
       "      <td>major design flaw high hope dress want work in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pants</td>\n",
       "      <td>1049</td>\n",
       "      <td>50</td>\n",
       "      <td>My favorite buy!</td>\n",
       "      <td>I love, love, love this jumpsuit. it's fun, fl...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>favorite buy love love love jumpsuit fun flirt...</td>\n",
       "      <td>favorit buy love love love jumpsuit fun flirti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Blouses</td>\n",
       "      <td>847</td>\n",
       "      <td>47</td>\n",
       "      <td>Flattering shirt</td>\n",
       "      <td>This shirt is very flattering to all due to th...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>flattering shirt shirt flattering adjustable t...</td>\n",
       "      <td>flatter shirt shirt flatter adjust tie perfect...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  class_name  clothing_id  usr_age             review_title  \\\n",
       "0  Intimates          767       33                        -   \n",
       "1    Dresses         1080       34                        -   \n",
       "2    Dresses         1077       60  Some major design flaws   \n",
       "3      Pants         1049       50         My favorite buy!   \n",
       "4    Blouses          847       47         Flattering shirt   \n",
       "\n",
       "                                         review_body  rating  recommended  \\\n",
       "0  Absolutely wonderful - silky and sexy and comf...       4            1   \n",
       "1  Love this dress!  it's sooo pretty.  i happene...       5            1   \n",
       "2  I had such high hopes for this dress and reall...       3            0   \n",
       "3  I love, love, love this jumpsuit. it's fun, fl...       5            1   \n",
       "4  This shirt is very flattering to all due to th...       5            1   \n",
       "\n",
       "                                          revs_lemma  \\\n",
       "0        absolutely wonderful silky sexy comfortable   \n",
       "1  love dress sooo pretty happen find store glad ...   \n",
       "2  major design flaw high hope dress want work in...   \n",
       "3  favorite buy love love love jumpsuit fun flirt...   \n",
       "4  flattering shirt shirt flattering adjustable t...   \n",
       "\n",
       "                                           revs_stem  \n",
       "0                  absolut wonder silki sexi comfort  \n",
       "1  love dress sooo pretti happen find store glad ...  \n",
       "2  major design flaw high hope dress want work in...  \n",
       "3  favorit buy love love love jumpsuit fun flirti...  \n",
       "4  flatter shirt shirt flatter adjust tie perfect...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Agregamos columna al dataset\n",
    "df['revs_lemma'] = reviews_lemma\n",
    "df['revs_stem'] = reviews_stem\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardamos dataset lemmatizado\n",
    "df.to_csv(path_or_buf='data/dataset_clothes_clean.csv', index=False) # Para que no guarde el índice como otra columna"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
